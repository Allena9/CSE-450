{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aUB4xrFdLkr8"
      },
      "outputs": [],
      "source": [
        "restart = True\n",
        "epoch_to_pickup = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XtiXE04uGB_U"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import contextlib\n",
        "import io\n",
        "import re\n",
        "import string\n",
        "import gc  # Import the garbage collector module\n",
        "import unicodedata\n",
        "from plyer import notification\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUgiww4oQ75T",
        "outputId": "329d5de7-4197-45e3-e5a4-76acde4a9c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "# Get a list of GPU devices\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "if gpus:\n",
        "    try:\n",
        "        # Enable memory growth for all GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        \n",
        "        # After enabling memory growth, we need to make sure TensorFlow sees the updated configuration\n",
        "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(f\"Error setting memory growth: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "irakMtGnaImf"
      },
      "outputs": [],
      "source": [
        "path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nDl6_okDOUyY"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# path = '/content/drive/My Drive/M6_Fall2023e/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv4r-dKnSRKz"
      },
      "source": [
        "## Functions for downloading text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xzLUaBa2Xmnb"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "\n",
        "    text = text.replace(\"Project Gutenberg\", \"\")\n",
        "    text = text.replace(\"Gutenberg\", \"\")\n",
        "\n",
        "    # Remove carriage returns\n",
        "    text = text.replace(\"\\r\", \"\")\n",
        "\n",
        "    # fix quotes\n",
        "    text = text.replace(\"“\", \"\\\"\")\n",
        "    text = text.replace(\"”\", \"\\\"\")\n",
        "\n",
        "    # Replace any capital letter at the start of a word with ^ followed by the lowercase letter\n",
        "    text = re.sub(r\"(?<![a-zA-Z])([A-Z])\", lambda match: f\"^{match.group(0).lower()}\", text)\n",
        "\n",
        "    # Replace all other capital letters with lowercase\n",
        "    text = re.sub(r\"([A-Z])\", lambda match: f\"{match.group(0).lower()}\", text)\n",
        "\n",
        "    # Remove duplicate whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
        "    text = re.sub(r\"\\t+\", \"\\t\", text)\n",
        "\n",
        "    # Replace whitespace characters with special words\n",
        "    text = re.sub(r\"(\\t)\", r\" zztabzz \", text)\n",
        "    text = re.sub(r\"(\\n)\", r\" zznewlinezz \", text)\n",
        "    text = re.sub(r\"(\\s)\", r\" zzspacezz \", text)\n",
        "\n",
        "    # Split before and after punctuation\n",
        "    for punctuation in string.punctuation:\n",
        "        text = text.replace(punctuation, f\" {punctuation} \")\n",
        "\n",
        "    # Makes sure that any non utf-8 characters don't make it through\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nFKehxVF9AxD"
      },
      "outputs": [],
      "source": [
        "def postprocess_text(text):\n",
        "\n",
        "    # Replace special words with whitespace characters\n",
        "    text = text.replace(\"zztabzz\", \"\\t\")\n",
        "    text = text.replace(\"zznewlinezz\", \"\\n\")\n",
        "    text = text.replace(\"zzspacezz\", \" \")\n",
        "\n",
        "    # Remake capital letters at beginning of words\n",
        "    text = re.sub(r\"\\^([a-z])\", lambda match: f\"{match.group(1).upper()}\", text)\n",
        "\n",
        "    text = text.replace(\"^\", \"\")\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtd9QyvUWqzi"
      },
      "source": [
        "# def getMyText():\n",
        "#   path_to_file = tf.keras.utils.get_file('austen.txt', 'https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/austen/austen.txt')\n",
        "\n",
        "#   text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "#   # path_to_file = tf.keras.utils.get_file('903-0.txt', 'https://www.gutenberg.org/files/903/903-0.txt')\n",
        "#   # author_text += open(path_to_file, 'rb').read().decode(encoding='utf-8')[2999:-19194]\n",
        "#   # tf.io.gfile.remove(path_to_file)\n",
        "\n",
        "#   return preprocess_text(text)\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def getMyText():\n",
        "    file_name = 'austen.txt'\n",
        "    file_url = 'https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/austen/austen.txt'\n",
        "    local_dir = './data/'  # Directory to save the file\n",
        "    local_path = os.path.join(local_dir, file_name)\n",
        "\n",
        "    try:\n",
        "        # Ensure the directory exists\n",
        "        if not os.path.exists(local_dir):\n",
        "            os.makedirs(local_dir)\n",
        "\n",
        "        # Check if the file exists locally\n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"File '{file_name}' found locally. Using it.\")\n",
        "        else:\n",
        "            print(f\"File '{file_name}' not found locally. Downloading it.\")\n",
        "            # Download the file\n",
        "            downloaded_path = tf.keras.utils.get_file(file_name, file_url)\n",
        "\n",
        "            # Save the downloaded file to the designated local directory\n",
        "            with open(downloaded_path, 'rb') as source_file:\n",
        "                with open(local_path, 'wb') as dest_file:\n",
        "                    dest_file.write(source_file.read())\n",
        "\n",
        "        # Read the file's contents\n",
        "        with open(local_path, 'rb') as file:\n",
        "            text = file.read().decode(encoding='utf-8')\n",
        "\n",
        "        return preprocess_text(text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multi Author text import\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Number of files to save\n",
        "files = 1\n",
        "\n",
        "def getMyText(count):\n",
        "    if(count == 1):\n",
        "        file_name = 'austen.txt'\n",
        "        file_url = 'https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/austen/austen.txt'\n",
        "        local_dir = './data/'  # Directory to save the file\n",
        "        local_path = os.path.join(local_dir, file_name)\n",
        "\n",
        "        try:\n",
        "            # Ensure the directory exists\n",
        "            if not os.path.exists(local_dir):\n",
        "                os.makedirs(local_dir)\n",
        "\n",
        "            # Check if the file exists locally\n",
        "            if os.path.exists(local_path):\n",
        "                print(f\"File '{file_name}' found locally. Using it.\")\n",
        "            else:\n",
        "                print(f\"File '{file_name}' not found locally. Downloading it.\")\n",
        "                # Download the file\n",
        "                downloaded_path = tf.keras.utils.get_file(file_name, file_url)\n",
        "\n",
        "                # Save the downloaded file to the designated local directory\n",
        "                with open(downloaded_path, 'rb') as source_file:\n",
        "                    with open(local_path, 'wb') as dest_file:\n",
        "                        dest_file.write(source_file.read())\n",
        "\n",
        "            # Read the file's contents\n",
        "            with open(local_path, 'rb') as file:\n",
        "                text = file.read().decode(encoding='utf-8')\n",
        "\n",
        "            return preprocess_text(text)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            return None\n",
        "    if(count == 2):\n",
        "        file_name = 'shakespeare.txt'\n",
        "        file_url = 'https://www.gutenberg.org/cache/epub/100/pg100.txt'\n",
        "        local_dir = './data/'  # Directory to save the file\n",
        "        local_path = os.path.join(local_dir, file_name)\n",
        "\n",
        "        try:\n",
        "            # Ensure the directory exists\n",
        "            if not os.path.exists(local_dir):\n",
        "                os.makedirs(local_dir)\n",
        "\n",
        "            # Check if the file exists locally\n",
        "            if os.path.exists(local_path):\n",
        "                print(f\"File '{file_name}' found locally. Using it.\")\n",
        "            else:\n",
        "                print(f\"File '{file_name}' not found locally. Downloading it.\")\n",
        "                # Download the file\n",
        "                downloaded_path = tf.keras.utils.get_file(file_name, file_url)\n",
        "\n",
        "                # Save the downloaded file to the designated local directory\n",
        "                with open(downloaded_path, 'rb') as source_file:\n",
        "                    with open(local_path, 'wb') as dest_file:\n",
        "                        dest_file.write(source_file.read())\n",
        "\n",
        "            # Read the file's contents\n",
        "            with open(local_path, 'rb') as file:\n",
        "                text = file.read().decode(encoding='utf-8')\n",
        "\n",
        "            return preprocess_text(text)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "rofy7hJ1iHVm",
        "outputId": "c0eaceda-482d-47a6-c54a-10c40d7aeaea"
      },
      "source": [
        "getMyText()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gsCd-ihOU02C"
      },
      "outputs": [],
      "source": [
        "def getRandomText(numbooks = 1, verbose=False):\n",
        "  # Create a buffer to capture download output messages\n",
        "  download_log = io.StringIO()\n",
        "  # Initialize empty string to store text from books\n",
        "  text_random = ''\n",
        "  # Loop through the requested number of books\n",
        "  for b in range(numbooks):\n",
        "    # Flag to track whether we've found a suitable book\n",
        "    foundbook = False\n",
        "    # Keep trying until we find a valid book\n",
        "    while(foundbook == False):\n",
        "      # Generate random book ID between 100-60000\n",
        "      booknum = random.randint(100,60000)\n",
        "      if verbose:\n",
        "        print('Trying Book #: ',booknum)\n",
        "      # Randomly choose between two URL formats for Project Gutenberg\n",
        "      if random.random() > 0.5:\n",
        "        url = 'https://www.gutenberg.org/files/' + str(booknum) + '/' + str(booknum) + '-0.txt'\n",
        "        filename_temp = str(booknum) + '-0.txt'\n",
        "      else:\n",
        "        url = 'https://www.gutenberg.org/cache/epub/' + str(booknum) + '/pg' + str(booknum) + '.txt'\n",
        "        filename_temp = 'pg' + str(booknum) + '.txt'\n",
        "      if verbose:\n",
        "        print('Trying: ', url)\n",
        "      try:\n",
        "        # Download the file, either showing progress or hiding it based on verbose flag\n",
        "        if verbose:\n",
        "          path_to_file_temp = tf.keras.utils.get_file(filename_temp, url)\n",
        "        else:\n",
        "          with contextlib.redirect_stdout(download_log):\n",
        "            path_to_file_temp = tf.keras.utils.get_file(filename_temp, url)\n",
        "        # Read the downloaded file and decode as UTF-8\n",
        "        temptext = open(path_to_file_temp, 'rb').read().decode(encoding='utf-8')\n",
        "        # Delete the temporary file after reading its contents\n",
        "        tf.io.gfile.remove(path_to_file_temp)\n",
        "        # Check if the book is in English\n",
        "        if (temptext.find('Language: English') >= 0):\n",
        "          # Add slight randomness to the starting position\n",
        "          offset = random.randint(-20,20)\n",
        "          # Skip the header/preamble text (typically first 2000 chars)\n",
        "          header = 2000\n",
        "          # Target length for extracted text\n",
        "          total_length = 200000\n",
        "          # Amount to trim from the end of the book\n",
        "          chopoffend = 10000\n",
        "          # For long books: extract a fixed-size chunk\n",
        "          if len(temptext) > (header+total_length+offset+chopoffend):\n",
        "            foundbook = True\n",
        "            text_random += temptext[header+offset:header+total_length+offset]\n",
        "            #print(\"Yes: \" + str(booknum))\n",
        "            if verbose:\n",
        "              print('New size of dataset: ', len(text_random))\n",
        "          # For medium-length books: take most of the book minus header and footer\n",
        "          elif len(temptext) > (header+12000):\n",
        "            foundbook = True\n",
        "            text_random += temptext[header:-chopoffend]\n",
        "            #print(\"Yes (smaller): \" + str(booknum))\n",
        "            if verbose:\n",
        "              print('New size of dataset: ', len(text_random))\n",
        "          # Skip books that are too short\n",
        "          else:\n",
        "            if verbose:\n",
        "              print('Not long enough. Trying again...')\n",
        "            #print(\"No: \" + str(booknum) + \" too short\")\n",
        "        # Skip non-English books\n",
        "        else:\n",
        "          if verbose:\n",
        "            print('Not English. Trying again...')\n",
        "          #print(\"No: \" + str(booknum) + \" not English\")\n",
        "        # Clean up memory\n",
        "        del temptext\n",
        "      # Handle any exceptions during download/processing\n",
        "      except:\n",
        "        if verbose:\n",
        "          print('Not valid file. Trying again...')\n",
        "        #print(\"No: \" + str(booknum) + \" not valid\")\n",
        "        foundbook = False\n",
        "    if verbose:\n",
        "      print(\"Found \" + str(b+1) + \" books so far...\")\n",
        "  # Clean up memory\n",
        "  del download_log\n",
        "  # The following commented code appears to be for further processing that was replaced\n",
        "  #text_random = \"\".join(c for c in text_random if c in vocab)\n",
        "  #all_ids_random = ids_from_chars(tf.strings.unicode_split(text_random, 'UTF-8'))\n",
        "  #ids_dataset_random = tf.data.Dataset.from_tensor_slices(all_ids_random)\n",
        "  #sequences_random = ids_dataset_random.batch(seq_length+1, drop_remainder=True)\n",
        "  #dataset_random = sequences_random.map(split_input_target)\n",
        "  #dataset_random = (dataset_random.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  #return dataset_random\n",
        "  \n",
        "  # Pass the collected text to a preprocessing function and return the result\n",
        "  return preprocess_text(text_random)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjEF0LKxhljS",
        "outputId": "c0e93e56-0db7-40b3-db3c-1aae811aed42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'austen.txt' found locally. Using it.\n"
          ]
        }
      ],
      "source": [
        "if restart:\n",
        "  vocab_text = getMyText(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpFvtyF_g3jY"
      },
      "source": [
        "Make vocabulary (Adapted from TensorFlow word embedding tutorial)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F8E6Q6dkMEpd"
      },
      "outputs": [],
      "source": [
        "# Vocabulary size and number of words in a sequence.\n",
        "vocab_size = 8192\n",
        "sequence_length = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AWXUqLQ6g3KB"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_string):\n",
        "    # Lowercase the text\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    \n",
        "    # Handle common punctuation marks one by one\n",
        "    # This avoids regex escaping issues\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\.', ' . ')  # Period\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r',', ' , ')   # Comma\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'!', ' ! ')   # Exclamation\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\?', ' ? ')  # Question mark\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r';', ' ; ')   # Semicolon\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r':', ' : ')   # Colon\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\(', ' ( ')  # Open parenthesis\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\)', ' ) ')  # Close parenthesis\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\[', ' [ ')  # Open bracket\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\]', ' ] ')  # Close bracket\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\{', ' { ')  # Open brace\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\}', ' } ')  # Close brace\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\"', ' \" ')   # Double quote\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r\"'\", \" ' \")   # Single quote\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'-', ' - ')   # Hyphen\n",
        "    lowercase = tf.strings.regex_replace(lowercase, r'\\*', '')   # Hyphen\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    return tf.strings.regex_replace(lowercase, r'\\s+', ' ')\n",
        "\n",
        "if restart:\n",
        "  # Use the text vectorization layer to normalize, split, and map strings to\n",
        "  # integers. Note that the layer uses the custom standardization defined above.\n",
        "  # Set maximum_sequence length as all samples are not of the same length.\n",
        "  vectorize_layer = TextVectorization(\n",
        "      standardize=custom_standardization,\n",
        "      split='whitespace',\n",
        "      max_tokens=vocab_size,\n",
        "      output_mode='int',\n",
        "      #output_sequence_length=sequence_length\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zJfr5w1bTWiJ"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  # Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "  vectorize_layer.adapt([vocab_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PmaoiyvF1Ilm"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  vocabulary = vectorize_layer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7ULNtM_8nYn"
      },
      "source": [
        "Save Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G1hjxv447INt"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  with open(path + \"vocabulary.txt\", \"w\") as file:\n",
        "    for word in vocabulary:\n",
        "        file.write(word + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7qn5MjC8p0_"
      },
      "source": [
        "Load Saved Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TLbSoqUP8Pxu"
      },
      "outputs": [],
      "source": [
        "if restart == False:\n",
        "  with open(path + \"vocabulary.txt\", \"r\") as file:\n",
        "      vocabulary = [word.strip() for word in file.readlines()]\n",
        "      vocabulary = vocabulary\n",
        "\n",
        "  vectorize_layer = TextVectorization(\n",
        "      vocabulary=vocabulary,\n",
        "      standardize='lower',\n",
        "      split='whitespace',\n",
        "      max_tokens=vocab_size,\n",
        "      output_mode='int',\n",
        "      #output_sequence_length=sequence_length\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FidGlurb1iD3",
        "outputId": "50b05e9e-68b7-4cda-a427-b879a3e3a5b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '[UNK]', 'zzspacezz', '^', ',', '.', 'the', 'to', 'and', 'of', '\"', 'a', 'her', '-', 'i', 'was', 'in', 'it', 'she', ';']\n",
            "['despicable', 'despatched', 'designing', 'designedly', 'descriptive', 'deranged', 'depriving', 'depreciating', 'deposit', 'dentist', 'demean', 'deliverance', 'deliberating', 'deigned', 'define', 'deduction', 'decree', 'declarations', 'decay', 'debates']\n"
          ]
        }
      ],
      "source": [
        "print(vocabulary[:20])\n",
        "print(vocabulary[-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LovypAGk91Yp"
      },
      "source": [
        "Turn text into a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Mnp0huUX93Wi"
      },
      "outputs": [],
      "source": [
        "# This function will generate our sequence pairs:\n",
        "def split_input_target(sequence):\n",
        "    input_ids = sequence[:-1]\n",
        "    target_ids = sequence[1:]\n",
        "    return input_ids, target_ids\n",
        "\n",
        "# This function will create the dataset\n",
        "def text_to_dataset(text):\n",
        "  all_ids = vectorize_layer(text)\n",
        "  ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "  del all_ids\n",
        "  sequences = ids_dataset.batch(sequence_length+1, drop_remainder=True)\n",
        "  del ids_dataset\n",
        "\n",
        "  # Call the function for every sequence in our list to create a new dataset\n",
        "  # of input->target pairs\n",
        "  dataset = sequences.map(split_input_target)\n",
        "  del sequences\n",
        "\n",
        "  # shuffle\n",
        "\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afRybxef_QHi"
      },
      "source": [
        "Test on vocab text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0tBa6ttN_Ufz"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  vocab_ds = text_to_dataset(vocab_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vq191mRgWv2w"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  text = ''.join([vocabulary[index] for index in ids])\n",
        "  return postprocess_text(text)\n",
        "\n",
        "vocabulary_adjusted = vocabulary\n",
        "vocabulary_adjusted[0] = '[UNK]'\n",
        "vocabulary_adjusted[1] = ''\n",
        "\n",
        "words_from_ids = StringLookup(vocabulary=vocabulary_adjusted, invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDqaTHXFAEBD",
        "outputId": "7dc76f61-3d65-4d2a-c8ca-6ff765949c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: \n",
            "tf.Tensor(\n",
            "[   3 2059    2    3   14    2    3  353    2    3   14    2    3  155\n",
            "    2    3  401    4    2  557    4    2 1075    4    2    8    2 1016\n",
            "    4    2   29    2   11    2  629    2  174    2    8    2  187    2\n",
            "  652    4    2  183    2    7    2 3688    2   98    2    9    2    6\n",
            "    2  271    2 3512    2    9    2 1802   19    2    8    2   24    2\n",
            "  815    2  899    2  636   13   75    2  340    2   16    2    6    2\n",
            "  241    2   29    2   36    2   96    2    7    2  709    2   57    2\n",
            " 4221    2   12    5    2    3   18    2   15    2    6    2 1758    2\n",
            "    9    2    6    2  122    2  548    2    9    2   11    2  108    2\n",
            "  943    4], shape=(128,), dtype=int64)\n",
            "Volume I Chapter I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her. She was the youngest of the two daughters of a most affectionate,\n",
            "tf.Tensor(\n",
            "[b'^' b'volume' b'zzspacezz' b'^' b'i' b'zzspacezz' b'^' b'chapter'\n",
            " b'zzspacezz' b'^' b'i' b'zzspacezz' b'^' b'emma' b'zzspacezz' b'^'\n",
            " b'woodhouse' b',' b'zzspacezz' b'handsome' b',' b'zzspacezz' b'clever'\n",
            " b',' b'zzspacezz' b'and' b'zzspacezz' b'rich' b',' b'zzspacezz' b'with'\n",
            " b'zzspacezz' b'a' b'zzspacezz' b'comfortable' b'zzspacezz' b'home'\n",
            " b'zzspacezz' b'and' b'zzspacezz' b'happy' b'zzspacezz' b'disposition'\n",
            " b',' b'zzspacezz' b'seemed' b'zzspacezz' b'to' b'zzspacezz' b'unite'\n",
            " b'zzspacezz' b'some' b'zzspacezz' b'of' b'zzspacezz' b'the' b'zzspacezz'\n",
            " b'best' b'zzspacezz' b'blessings' b'zzspacezz' b'of' b'zzspacezz'\n",
            " b'existence' b';' b'zzspacezz' b'and' b'zzspacezz' b'had' b'zzspacezz'\n",
            " b'lived' b'zzspacezz' b'nearly' b'zzspacezz' b'twenty' b'-' b'one'\n",
            " b'zzspacezz' b'years' b'zzspacezz' b'in' b'zzspacezz' b'the' b'zzspacezz'\n",
            " b'world' b'zzspacezz' b'with' b'zzspacezz' b'very' b'zzspacezz' b'little'\n",
            " b'zzspacezz' b'to' b'zzspacezz' b'distress' b'zzspacezz' b'or'\n",
            " b'zzspacezz' b'vex' b'zzspacezz' b'her' b'.' b'zzspacezz' b'^' b'she'\n",
            " b'zzspacezz' b'was' b'zzspacezz' b'the' b'zzspacezz' b'youngest'\n",
            " b'zzspacezz' b'of' b'zzspacezz' b'the' b'zzspacezz' b'two' b'zzspacezz'\n",
            " b'daughters' b'zzspacezz' b'of' b'zzspacezz' b'a' b'zzspacezz' b'most'\n",
            " b'zzspacezz' b'affectionate' b','], shape=(128,), dtype=string)\n",
            "Target: \n",
            "tf.Tensor(\n",
            "[2059    2    3   14    2    3  353    2    3   14    2    3  155    2\n",
            "    3  401    4    2  557    4    2 1075    4    2    8    2 1016    4\n",
            "    2   29    2   11    2  629    2  174    2    8    2  187    2  652\n",
            "    4    2  183    2    7    2 3688    2   98    2    9    2    6    2\n",
            "  271    2 3512    2    9    2 1802   19    2    8    2   24    2  815\n",
            "    2  899    2  636   13   75    2  340    2   16    2    6    2  241\n",
            "    2   29    2   36    2   96    2    7    2  709    2   57    2 4221\n",
            "    2   12    5    2    3   18    2   15    2    6    2 1758    2    9\n",
            "    2    6    2  122    2  548    2    9    2   11    2  108    2  943\n",
            "    4    2], shape=(128,), dtype=int64)\n",
            "volume I Chapter I Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her. She was the youngest of the two daughters of a most affectionate, \n"
          ]
        }
      ],
      "source": [
        "if restart:\n",
        "  for input_example, target_example in vocab_ds.take(1):\n",
        "    print(\"Input: \")\n",
        "    print(input_example)\n",
        "    print(text_from_ids(input_example))\n",
        "    print(words_from_ids(input_example))\n",
        "    print(\"Target: \")\n",
        "    print(target_example)\n",
        "    print(text_from_ids(target_example))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Rp402vgrS54t"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "def setup_dataset(dataset):\n",
        "  dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0LdoMfT7T8WN"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  vocab_ds = setup_dataset(vocab_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VQ-KjEeZMzd"
      },
      "source": [
        "## III. Build the model\n",
        "\n",
        "Next, we'll build our model. Up until this point, you've been using the Keras symbolic, or imperative API for creating your models. Doing something like:\n",
        "\n",
        "    model = tf.keras.models.Sequentla()\n",
        "    model.add(tf.keras.layers.Dense(80, activation='relu))\n",
        "    etc...\n",
        "\n",
        "However, tensorflow has another way to build models called the Functional API, which gives us a lot more control over what happens inside the model. You can read more about [the differences and when to use each here](https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html).\n",
        "\n",
        "We'll use the functional API for our RNN in this example. This will involve defining our model as a custom subclass of `tf.keras.Model`.\n",
        "\n",
        "If you're not familiar with classes in python, you might want to review [this quick tutorial](https://www.w3schools.com/python/python_classes.asp), as well as [this one on class inheritance](https://www.w3schools.com/python/python_inheritance.asp).\n",
        "\n",
        "Using a functional model is important for our situation because we're not just training it to predict a single character for a single sequence, but as we make predictions with it, we need it to remember those predictions as use that memory as it makes new predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Fj4uh9y-Y9mx"
      },
      "outputs": [],
      "source": [
        "# Create our custom model. Given a sequence of characters, this\n",
        "# model's job is to predict what character should come next.\n",
        "class AustenTextModel(tf.keras.Model):\n",
        "\n",
        "  # This is our class constructor method, it will be executed when\n",
        "  # we first create an instance of the class\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__()\n",
        "\n",
        "    # Our model will have three layers:\n",
        "\n",
        "    # 1. An embedding layer that handles the encoding of our vocabulary into\n",
        "    #    a vector of values suitable for a neural network\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # 2. A GRU layer that handles the \"memory\" aspects of our RNN. If you're\n",
        "    #    wondering why we use GRU instead of LSTM, and whether LSTM is better,\n",
        "    #    take a look at this article: https://datascience.stackexchange.com/questions/14581/when-to-use-gru-over-lstm\n",
        "    #    then consider trying out LSTM instead (or in addition to!)\n",
        "    #self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
        "    self.lstm1 = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "    self.lstm2 = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "    self.lstm3 = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "    self.lstm4 = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "\n",
        "\n",
        "    self.hidden1 = tf.keras.layers.Dense(embedding_dim*64, activation='relu')\n",
        "    self.hidden2 = tf.keras.layers.Dense(embedding_dim*16, activation='relu')\n",
        "    #self.hidden3 = tf.keras.layers.Dense(embedding_dim*4, activation='relu')\n",
        "\n",
        "    # 3. Our output layer that will give us a set of probabilities for each\n",
        "    #    character in our vocabulary.\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  # This function will be executed for each epoch of our training. Here\n",
        "  # we will manually feed information from one layer of our network to the\n",
        "  # next.\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "\n",
        "    # 1. Feed the inputs into the embedding layer, and tell it if we are\n",
        "    #    training or predicting\n",
        "    x = self.embedding(x, training=training)\n",
        "\n",
        "    # 2. If we don't have any state in memory yet, get the initial random state\n",
        "    #    from our GRUI layer.\n",
        "    batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "    if states is None:\n",
        "      states1 = [tf.zeros([batch_size, self.lstm1.units]), tf.zeros([batch_size, self.lstm1.units])]\n",
        "      states2 = [tf.zeros([batch_size, self.lstm2.units]), tf.zeros([batch_size, self.lstm2.units])]\n",
        "      states3 = [tf.zeros([batch_size, self.lstm3.units]), tf.zeros([batch_size, self.lstm3.units])]\n",
        "      #states4 = [tf.zeros([batch_size, self.lstm4.units]), tf.zeros([batch_size, self.lstm4.units])]\n",
        "    else:\n",
        "      states1 = states[0]\n",
        "      states2 = states[1]\n",
        "      states3 = states[2]\n",
        "      #states4 = states[3]\n",
        "    # 3. Now, feed the vectorized input along with the current state of memory\n",
        "    #    into the gru layer.\n",
        "    x, state_h_1, state_c_1 = self.lstm1(x, initial_state=states1, training=training)\n",
        "    states_out_1 = [state_h_1,state_c_1]\n",
        "\n",
        "    x, state_h_2, state_c_2 = self.lstm2(x, initial_state=states2, training=training)\n",
        "    states_out_2 = [state_h_2,state_c_2]\n",
        "\n",
        "    x, state_h_3, state_c_3 = self.lstm3(x, initial_state=states3, training=training)\n",
        "    states_out_3 = [state_h_3,state_c_3]\n",
        "\n",
        "    #x, state_h_4, state_c_4 = self.lstm4(x, initial_state=states4, training=training)\n",
        "    #states_out_4 = [state_h_4,state_c_4]\n",
        "\n",
        "    states_out = [states_out_1, states_out_2, states_out_3]#, states_out_4]\n",
        "    #states_out = [states_out_1, states_out_2]\n",
        "\n",
        "    x = self.hidden1(x,training=training)\n",
        "    x = self.hidden2(x,training=training)\n",
        "    #x = self.hidden3(x,training=training)\n",
        "    # 4. Finally, pass the results on to the dense layer\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    # 5. Return the results\n",
        "    if return_state:\n",
        "      return x, states_out\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NGm9o_J8Tq2F"
      },
      "outputs": [],
      "source": [
        "if restart:\n",
        "  dataset = vocab_ds\n",
        "  del vocab_text\n",
        "  del vocab_ds\n",
        "else:\n",
        "  new_text = getRandomText(numbooks = 10)\n",
        "  dataset = text_to_dataset(new_text)\n",
        "  del new_text\n",
        "  dataset = setup_dataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UA2C6pxZc4De"
      },
      "outputs": [],
      "source": [
        "# Create an instance of our model\n",
        "#vocab_size=len(ids_from_chars.get_vocabulary())\n",
        "embedding_dim = 128\n",
        "rnn_units = 512\n",
        "\n",
        "model = AustenTextModel(vocab_size, embedding_dim, rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C67kN7YAdfSf",
        "outputId": "87af41fd-6cbe-4d7b-9ff9-2cdce14a280d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 128, 8192) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# Verify the output of our model is correct by running one sample through\n",
        "# This will also compile the model for us. This step will take a bit.\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "qJGL8gCWdsiu",
        "outputId": "fe8a8959-c379-4369-83dc-22dba8d4e3d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"austen_text_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  1048576   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  1312768   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  2099200   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                multiple                  2099200   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                multiple                  0 (unused)\n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  4202496   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  16779264  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  16785408  \n",
            "=================================================================\n",
            "Total params: 44,326,912\n",
            "Trainable params: 44,326,912\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Now let's view the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UDbtrI9tc2NH"
      },
      "outputs": [],
      "source": [
        "# Here's the code we'll use to sample for us. It has some extra steps to apply\n",
        "# the temperature to the distribution, and to make sure we don't get empty\n",
        "# characters in our text. Most importantly, it will keep track of our model\n",
        "# state for us.\n",
        "\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, vectorize_layer, vocabulary, temperature=1):\n",
        "    super().__init__()\n",
        "    self.temperature=temperature\n",
        "    self.model = model\n",
        "    self.vectorize_layer = vectorize_layer\n",
        "    self.vocabulary = vocabulary\n",
        "    #print(\"initialized\")\n",
        "\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "    skip_ids = StringLookup(vocabulary=list(vocabulary))(['', '[UNK]'])[:, None]\n",
        "    #print(skip_ids)\n",
        "    #print(\"3\")\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices = skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(vocabulary)])\n",
        "    #print(\"4\")\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask,validate_indices=False)\n",
        "    #print(\"5\")\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    #input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.vectorize_layer(inputs)\n",
        "    #print(input_ids)\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states =  self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    del input_ids\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    del predicted_logits\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    #print(predicted_ids[0])\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return words_from_ids(predicted_ids), states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "P3WQoFaE7Ol2"
      },
      "outputs": [],
      "source": [
        "def produce_sample(model, vectorize_layer, vocabulary, temp, epoch, prompt):\n",
        "  # Create an instance of the character generator\n",
        "  #print(\"entered\")\n",
        "  one_step_model = OneStep(model, vectorize_layer, vocabulary, temp)\n",
        "  #print(\"rand one step\")\n",
        "  # Now, let's generate a 1000 character chapter by giving our model \"Chapter 1\"\n",
        "  # as its starting text\n",
        "  states = None\n",
        "  next_char = tf.constant([preprocess_text(prompt)])\n",
        "  result = [tf.constant([prompt])]\n",
        "\n",
        "  for n in range(200):\n",
        "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "    #print(next_char)\n",
        "    result.append(next_char)\n",
        "    #print(result)\n",
        "\n",
        "  result = tf.strings.join(result)\n",
        "  #print(result)\n",
        "\n",
        "  # Print the results formatted.\n",
        "  #print('Temp: ' + str(temp) + '\\n')\n",
        "  print(postprocess_text(result[0].numpy().decode('utf-8')))\n",
        "  #print('\\n\\n')\n",
        "  print('Epoch: ' + str(epoch) + '\\n', file=open(path + 'tree.txt', 'a'))\n",
        "  print('Temp: ' + str(temp) + '\\n', file=open(path + 'tree.txt', 'a'))\n",
        "  print(postprocess_text(result[0].numpy().decode('utf-8')), file=open(path + 'tree.txt', 'a'))\n",
        "  print('\\n\\n', file=open(path + 'tree.txt', 'a'))\n",
        "  del states\n",
        "  del next_char\n",
        "  del result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTDe5m4baEqo"
      },
      "source": [
        "## IV. Train the model\n",
        "\n",
        "For our purposes, we'll be using [categorical cross entropy](https://machinelearningmastery.com/cross-entropy-for-machine-learning/) as our loss function*. Also, our model will be outputting [\"logits\" rather than normalized probabilities](https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow), because we'll be doing further transformations on the output later.\n",
        "\n",
        "\n",
        "\\* Note that since our model deals with integer encoding rather than one-hot encoding, we'll specifically be using [sparse categorical cross entropy](https://stats.stackexchange.com/questions/326065/cross-entropy-vs-sparse-cross-entropy-when-to-use-one-over-the-other)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mOP5s0SmIhUO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'austen.txt' found locally. Using it.\n"
          ]
        }
      ],
      "source": [
        "sherlock_text = getMyText(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSk7HBJe_RZi"
      },
      "source": [
        "if restart == False:\n",
        "  model.load_weights(path + \"lstm_gru_SH_modelweights_fall2023-random_urls.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vOxc7CkaGQB",
        "outputId": "5524a5d1-2723-421e-9d05-de13ff75ab0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "180/180 [==============================] - 18s 87ms/step - loss: 3.6524\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Great I a Lord A I a I a Hundred of the I be a I of the I be be be that the I be the I the I the I, the I the I be be to would been that to a own well on the I be the part of the I to I be a own number, of the I a I be I to the I I Day A Society On The The I the I\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It the Life, I a own I the I a I be be be had not a very greater hills, of the I do the I be be a father of the When the I be be be at the I a own more be be not been the Lord The George, He and a magnificent a hand of the I a I to the whole have be be the I more the I be a own be that of the I to with the I be be\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. And the I see the French For In the France H L L--In X The It On To A Hand In After I One Would Day D. Hearts ---------------------------------------------------------------------------------------------------------------\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He the See, with the United Well was to I At Cut his I have have be be of it are be up on a Mark London I, One in Papers S said A A I are a new Mark As the I be lead and the Old York I in the I to 'the I get added of the I already had will were that will with well after the fine take that a not given by I a south and the I.\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He the O.; He among what the life be a I the I of the state of, we had look or egg, we member of the The French The present of I a important had is at the way to at Western 'Would the 3 of air of the future, of there of Powers but be is have had when the larger have, by the I would set with the many suspicion that of the two afraid to the uncle of England, half again that no coarse in the\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. In A feel which the eye of, part all teach another had be that the world will not the blood, and the force and which small made out he campbell the two sent of the immediately established had back. In me, he, with he get, who within when War as I have at Upper \"In the walls is in legs of I by that that _With the April of a sea Lord. The Great Here. The very height, and a own clear, that man. But \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  1\n",
            "167/167 [==============================] - 16s 87ms/step - loss: 2.6280\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It is not be not be for the United Of French Day, The University Of Of Of Of Of The Of Of The Of Of Of Of Of History A Of Of Of Of Of Of Of Of Of The Of Of Of Of The Of Of Of Of Of The Work Of The Of Of Of Of The Use Of Of Of Of Of Of Of The \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. In the United Of Of Of Prayer Of Of Of Of The Lord Of For A Of Of Of Of Of Of Of Days The Of Of Of The Day The Of Of The Of Sea. The History Of Of Of Of The Sea Of Of Education Of The Of Of Of Of Of The Of Of Of Of The That Of The Of Of Of\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. When you found the Parish Prayer. At Lord Nights, I am the Prayer No Prayer The Of Path Of The Circle, The Months Of Man Shakespeare Of Of The Use Of Of Of Use And The Days Of And Of By Top Of Or The Of Of Story, You The Story of And Painters The Of Of Of The Of York Of The Service Of The To\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. But he was no good _I, I am your companions, and to me to make the best happy of the United I kept I think to find the same son for the Curate makes the whole side of the midst of the English considerable Church, that the United Of Chapel Prayer. For Fish First, that Project A introduction of a Places History the Order of Of Night Or Four Life Family Son. The Foundation Of Of Of The Lesson\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. In the Parish shall have three for the entire of the Parish of his imagination, they had been forth, but he must seek be a few years had like the son, and the picture to be to be few leaf. The Third London D For At Of Equals The Of Year Of H, May Sadness Reform, Sir Eyes, I have not do read the desert, the man was trim the use of the most are an city and her. We would have been at\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. They year in his deep-days of York Edward- 4 Horse. In the light of -book of the ground 1. From this Sunday might of Have only the Works, and the Assembly is Great Society_-in Prayer to half By Of Blue. Its Ages Apparent Family, This Of State, I did all these of the Party of Who life in addition which him eating no gentleman, they no. It was almost into his hands to get up a gentleman. The\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  2\n",
            "171/171 [==============================] - 16s 88ms/step - loss: 2.4981\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. I was to be as to the Free To His To His And The Of Of The Of Of Of The Of Of The Of Of The Of \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. I was to the Red Cross Of Of The Work Himself Of Of Of The Of Of Of The English Of Of Of Of Of The \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The woman was a new fire, and the Red Cross of the Red Mill. She was to the French Gentlemen was to my name to his mother and there had shown that I was no one of Miss Mantel, I had no one of the Red, and Betty Stop, and she were to be a moment as a hat to be of the God. I had shown to I should be seen in the United Himself in this Law, and I went in the French\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The very first of the Universal. He was a French With Son A Men Of Family Of A Years Of The Of Of Of Conference Of The Men Of Dream Of Of The Of And Of  --\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. They were accepted to care to the residence of the night of Italian Cross. A lord was to all the great morning, and up on the road and the Great Hill's Room State Silk Of Of Of Were Men Of In Of Of Of Of The Of Of In Whose Of Morning Of Of Of The Of Of Or People Of Of Of Of The Of Of And Of Of Of In\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. She had ever left the former side of the \"Club. But we could be a human voice, I know nothing to assist her way. But I could our honour on that I could find anything for within the acquisition of Camp Viii.. Thus If Or At Truth The Power In Of Compassion In His Gentleman In Of Of The One Of Way the Man. Who was that They call that He was at England, it with the first \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  3\n",
            "164/164 [==============================] - 15s 88ms/step - loss: 2.4345\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The King Henry Lee Lee Of York Lee Lee Of New York Of The King Of The King The Stamp York And The War Of The War Of The Name Of The Of The Of Of The Of The \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He had no longer able to be an other more than an more years who who had been able to be able to be able to learn to be a new master and a doubt of the United England in the King of England and King, and the English King Henry Lee at England in October York and Times Henry Lee And In General Act Of The House Of The King Of The Way The Book Of The Two Of \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He was not not been on him, and he had been expected to be always because he had been able to set on them he turned with the House who had been more in the King Of War York Lee who A King List Of Lee And  And Of Name Of The Of The The The Of The Of The The \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Then he was the answer of Mr. Lee, \"in my time's mind I have been able to wish it is gone to be less for having done. Just are a very time to be a matter of train till we are made any law to think of the same people has removed in the people to be used for a man of the most important desire to be necessary in the world. If they are of the great of those who has not be able to say, he is made a great course\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The summer were a new bewildered, and the time were also, and in a new spirit was for a knowledge of the river. The captain Was every hour he had count that came to a great sign, and there had not always been had been used to sing. Henry, it was not made a friend and traced a hands of them. In the King had many were an resolute hour. \"I shall lead them at me to make my father in all the old King, we will simply in them as\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Object was distant between his arms. The old man was a fool. \"Yes,\" said Mrs.. 'I have the letter outwardly,\" we offered whatever he but the future Dr. Henry, and it was slowly and led to his own place with the whole and Master. He walked in a basket. But cannot send too have just sorry to be chosen with the sitting with her own times little young and undoubtedly progress of the old man. D. He made the ways of its torture. The angry\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  4\n",
            "155/155 [==============================] - 15s 88ms/step - loss: 2.3274\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He had been a body of the Castle of John Valley and Margaret, and the Estate was not in the English Square in the Little Red Doctor George Charles John George E. I am glad to be a little deal of the Soul.\" The Little Red Doctor I had been a good man and the Master John John Junior. She was a great deal of the Lady Elizabeth, and I had been a small deal of his own life. I \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He had been the Sun of S---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He had seen many other to the effect of the Queen of Nature, I was sure that he had the late of Mr. Anderson (\"I went to Henry to me her husband, I am a good girl in Miss William of the affections, and that I am you and if you are anxious to think that you will be to forget to you this I am the strong thing for I can have to be too long of the Acre of I have a little chance of thou much\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. A most sent in Margaret-s things.\" She was as he had come to the table and the Lord and the letter and Margaret and the father was to be of the Hotel of the Charity Last Lodge, An Merciful A Children Woman--Her Dinner, and Red Doctor Hill Tom I'd been four years for the Little Square to Lady William John John John William and I found a husband to the Boy--I will. \"If I should\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. And which one was a flat of Henry in his childhood he was in an time. A few were heard the dreadful of his father could be no longer--for her time. She was no ridicule. \"He would be to Sunday at Mr.\" I began to do to be for a serious part between the school of the Park that he found that Mrs. Dick and April a pew, of a like decency and set him! And she was the most serious man, to you think God,\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London.\" From Safety his own possession, the husband of the young country's power. The servant-to my son is Philosophy together and all, by the Masters of Mary Pope, but Walter Society--to Sun Chapter A Present To You Built Daughter. The Child Easter Stile s, is established with his mind in this thing. He had given me more to be, and created tenderness by it, and a time, I think he thinks to pass me at all as I feel running\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  5\n",
            "178/178 [==============================] - 17s 89ms/step - loss: 2.3204\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Grandmother was not in the General Church Point Of The Old York Of The Chapel The Village Of The Bridge Of The Library Of The Tree Of The The Old Church Of The Old Club The Old House Harbour Of The Harbour Of The Dining-Room Of The       \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The General Of the Castle Of The Old York Of The Old Church Of The Chapel Of The Old House Of The Dining Room The Harbour                                               \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The whole was the Grandmother heard his face and his Betty and went to him, and the Grandmother and he had taken him and he had attacked her. The storm was a good deal of the English ship and Mrs. Bennet. \"Oh, I have promised to tell you.\" \"What is a General. She is the General to New York The Great Mysteries of The House Of The Church Of The Part Of The Duke Of The Chapel Of\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. They were in the north of the Gothic Church In the United By The Literary Life The Garden Before The Point And The Court Of The Old Hall The Old House Of Of The Old Garden Of House A Old Room And A Old Harbour And A Old House Of The The Home  Of The Edition Of Name Of The Before Old Into Room. Ii. The\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. These of the north of the Irish The Third Chapter Xi. To The East Entrance: A Dining Letter The And Two Bridge   Harbour The Bridge The Entrance And The Lake 5. The Head The Old Church Lake A House The Dining-Foreign Old France The House Chapter First. Of Our To : The Stream Chapter 5.Xiii. How The Seven Duke Acre On Of \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The really George de Hero and married, He after his Margaret de Betty in his death. She left Astleys Phillips, Elevating Butler At home the play of Gardens first had given your good a noble lot of behaviour the isle of his country, and his brother--\" Poor Mill, the General of New York, Mount Edward George Iv. Of King Mary The Manager Family The Channel Of The Country The Lake Of This. The Lakes \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  6\n",
            "183/183 [==============================] - 17s 89ms/step - loss: 2.2495\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Queen Of the Company Of The Act of The City of France--The State--The Project--The People--The Loss--The Body--The People--The New--Manners--The Manners--The Of--Manners--Manners--Of Manners--The Office--Manners--Manners--Manners--Manners--Manners--Manners--Manners--Observances--Manners--Manners--Manners--Motion--Motion--Or Motion--Motion--Weight\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Vice-House Of The Construction Of The Queen Of The Third Of The Duke of The State--The Year--The Whole Nation--The Rest--The Nation--The People--A And Manners--The Person--Of Duties--Appointed--Attentions--A Manners--Manners--Observances--Manners--Motion--The Same--Duties--The Person--People--The People--The People--The And Dress--Dress--\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Club was in the United Society, and the London Door, which he was the Daughter Of Lieutenants I was very much acquainted with an old lady of the General Forest I was a little English and a quarter of the Court. I am sure that is your own heart. I don't think it is too many of your company. I hope you are so much about a person than I'm going to get the room, and what you are to see your I want\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. On the morning we started again again a fall at the A Ball Club (The Larger--The Tree Of Lane-The County--A Young-Book--T-The Man and Commendation--The Sound--And Minds--Life--Powers--Of Motion--An And Before Moments--Manners--A Crime--S.--Necessity--Harmony--The World--A Author Of Manners--Manners--A Subjects--Work--With And--Observances--A-\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. A mere pretty little good men had carefully been looking into the hand of another woods, and I had to give to the London, and had long been a great sum that Mrs. Thomas Account was occupied in the French office. Upon the first Captain Ii. The King Of the Lady Of John--The Water--The Volume--An Gravity--A Economy--The Body--Of Natural Manners--The Weight--What is called the Strength--A Particular-\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He was staying to continue to get out on the afternoon. When she thought, the observation could be able to hear that the boys were under a good one, and had resulted at the acquaintance. \"I have spoiled with the other and two that both of the Church and the White Count  .\" \"No,\" said the Vice-Red Attempted to lose her sudden, and at half, closed in its other knowing, where, when the night guessed her things were ready, the hope of bury his meanness was\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  7\n",
            "174/174 [==============================] - 16s 89ms/step - loss: 2.2415\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. I was a great deal of the King of France, and the Army of Sir Thomas Colonel John James John of Sir Thomas Hill of Sir Thomas Strange Army to Sir Thomas Sir Thomas Thomas Sir John Sir John Elizabeth of Sir George George John Sir Gilbert Strange Commission of Sir Thomas Chief in the Church of John Andrews in March to Sir Thomas Strange Edition of John S. The War of Sir \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. In the end of the West of July the English City were made to be described to Sir Thomas Fairfax (I have been the first edition of the Civil War, the Civil War of W. March of New York, John Thomas House Of The Sea of London The Church Of The Works (_The Literary Enforced_). The French Edition (_C_). The Civil War (\"C.S.T.\" In New \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He was in the war to the King Council of New York, and the daughter of Scotland he had been in Scotland in the Spirit of Sir George I. It was a Colonel D. The Edition of York The War of Mr. Strange, Sir James John I was not born to Sir John Hardy, John John S, John E. Smith, John Of John of Captain Strange Title of New York (A Years of\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. To the building of the Scotch City (F.W. New York. 16 volumes of the King of West Edition of New Work. The Literary Title of Book (_E.S.S._. New edition have been shown to the First Title of York (Note), and Edition of Thomas Castle, and Mr. Fairfax (_A_) signed by the first time was now prevented by some trial to pay their heads to profit, and there was a writer in the \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. We are not prepared to wait to believe that this is not here for the day of Sir. At which, when us I was \"The Queen of March of Verses\" And my report of land I believe not to be set from the people that I sought myself in this field, was altogether a truth of the Hills of English House.\" \"Yes,\" he came down to say that I was already married, she was a famous name of England, and often refused him to know.\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Range were up to meet the night by New York to S. The North of Hill in June the following year Sir The First Edition] By The Title of Parliament When I made Boy Viii. In March Stoke Chapter Chapter X This Title Of \"The Baby of Money Church\" (\"C.S.\" I I take a good account of Mr. F. E. S.S., was a Place and Or Use, while\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  8\n",
            "139/139 [==============================] - 13s 88ms/step - loss: 2.1868\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It was not a great Person of God. The King Ii The World Of The Little Little Cousin The Little Cousin Our Little Cousin Our Little Irish Cousin Our Little. I I have a King And Cousin Our Little Cousin Our Little Cousin Our Little Cousin Cousin Our Little Cousin Our Little Cousin Cousin Our Little Cousin Cousin Our Little Cousin Our Little Cousin Cousin Our Little Cousin \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. There were three fish that were a most interesting and more than the Italian House River. The West Ages Of The World Of The Introduction Of The Little Cousin The Little Cousin Our Little Cousin Our Little Cousin Cousin Our Little Cousin Cousin Our Little Cousin Cousin Our Little Cousin Our Little Irish Cousin. I I Not Did I Not I have been as one of them? But I am not informed that\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. They were master of the Pope, who was a great Person of the French, who had no one was a Formal Army in the Inn Road. It was always needless to be allowed to be brought in the three dead who were one of the French Hill. The vicinity of St. George Ii. The Lord Ferrars was not but the Son of God, and the Divine Nature was not united to the Divine Person. Therefore it was a medium of a person in \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The King had gone to the Mighty Cottage, which was a English smile; and the King led Dr. George, and Dick had been the first to be ten years older than a young man who was not all the place of Mr. Ferrars, and her son had been so of his wife that the King was not permitted to give me in the German Ireland. He was not tired of business, and I found it to be the darling of the fairy English Land, and the \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It were not a fair for the family. Yet my Government, and proceeding to that three hearts were not past the period of the King, and he was running that he had been born of Dick and Him has been in the Year Foundation, I cried. But there was great interest and respect of a kind price of so quick; it was quite a Place in the Place of His War, which he felt greatly that he was destined to have good sentiment in the man's regiment, and\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It is certainly the separation of God to work can be plain. But, because it is a Divine nature is not the Divine to the body, and we have according to it. 1: We must always find us in your neighbourhood, and when the new of the man was apt to be taking up as a tenant of the world. Now one thing may be of possessions, and at Him, like more? Then no real stately selection had a retirement. Later this rejoiced given in a year with the \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  9\n",
            "153/153 [==============================] - 14s 88ms/step - loss: 2.1754\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The New York Valley was a Christian manuscript of the Christian Church, and the Old York of Charles H. The Old York Xvi. The New York Of The Hall of The New Cross Chapter Iii. The Second Hall of The Dead Of The New House of The Project --The Project Project ---------------------------------------------------\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The next morning I saw all the King Dick and Dick A. The Stranger was not at once to act to go to London. He had not been able to build the New France. He was a very fine man on the English Bridge, where he had been sent to the King of Charles. As the New York House, and the French Alliance, Henry, the French, was the Baron of John Iii. Iii. King Butler's Father. \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The whole idea of the Second House of William Butler, Henry, and Mrs. Bartlett Butler and Mr. Butler and New York. The Baron William Butler was adopted at Oxford, and was in the French Christian House, where he was to have been in the death of John Iii. The Christian Government is not in the United I. The Word of the Great Work is the Union of the Old Union, except in the United I. \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. They were frequently active to number of Scotland for the Indian Abbey as a French proportion to the Old Church. The French of Mrs. Butler wrote to the Purple Sea. A great example was now not to take it to him. It was deemed a very different matter of use to the Irish state of Mrs. Ii. He is not the condition of the Old War War in a day of the first to the Government of France. The Prime of the French\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. If, I have had never felt a mystery where I had never seen him. And it was true that the girls a whole newspaper had taken down to love. \"The Father Jones, and \"The Language\" \"The Lady,\" says Mr. Apricot; \"but King Walter I have not used somewhere of us to know how to speak to my sister. That is very well, I must have just been heard here. Your Lord I had said that I had already no words who\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. His State is in London from I Pens during August John, a \"Book\". So called he himself sent in an inmate of the old, as a rule we had gained the English or the fatal school of S Masters, were founded in the Court. It is to show that the name of Irish men adopted in the year that they are hinted in that of the public duty involved fuller to him. The Old Man alone tells us I know all of my heart who will \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  10\n",
            "245/245 [==============================] - 22s 88ms/step - loss: 2.2437\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It was a very different one to her in the world, and she had never seen her to be of her own life; and she was not so busy as she could have been in the room, and it was not to be found to be the last time of the Parsonage at the park, and that she was not to be her own and the whole family with the Tilneys Square, of which she had not been so much in the world, and she was not aware of it to be quite impossible for\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Miss Bertrams were at Weymouth and the Captain Wentworth in a few minutes of the house, and Mrs. Ferrars would have been in the room, and that Marianne had no objection to her own the Eltons, was her own brother and sister. The visit was soon to another of the Parsonage, as he had talked to her in the room, and Captain Wentworth was in the drawing-room in the drawing-room, and Mr. Darcy was gone. The Miss Steeles was at Hartfield, \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The disadvantages of the Tilneys were now brought to Mansfield Park on such a time of life. He was a very good-humoured girl, and she was delighted with the great of the three sisters who had been a man of age, and all the pleasures of the day were at Hartfield. \"Well, I am sure,\" said Elinor, with a hope of speaking to him with a smile; \"but I am not certain of being married in company this morning.\" \"Indeed you ought to have been more \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. He was now a very different business. Miss Bingley was pleased with the intelligence of her situation; and with the affection she was not a very gentlemanlike man, which could not be seen by the belief herself to be my behaviour to him, during the end of the present evening, he seemed to come into the East room, and then two thousand a very handsome fellow was at home; and upon the contrary, he would be all the satisfaction of her sister and herself in the Cottage, who had been a certain time\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Mr. Rushworth was absent; he sat down to the cottage. Her affection and a  -boy had been used to fancy his fortune, and she was quite sorry for her mother was so much to Mansfield Park, by the principal parts of Dr. Jennings, who came down. Chapter 18 The Five Rooms were, Marianne, and Portsmouth, and a well-known brother must be in time to say whether possible ceased for her. She could not have found either of them, and every attention concluded on Emmas\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. A few minutes would soon find the It said for; but he had got anywhere but being simple. The sister would have felt enough to be immediately, standing over him for Mr. Tilney. Chapter Xii Mr. Wickhams opinion could not be suffered than herself. Chapter 22 This was the whole of the first thing of a fox-book, who belonged to her conviction as a very ungrateful; and carried down farther and imagined their only attention; and after degrees at length she returned to Jane the fire with describing\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  11\n",
            "245/245 [==============================] - 22s 88ms/step - loss: 2.0721\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It was a great relief to Mrs. Jennings and Mrs. Jennings, and Mrs. Jennings was a good deal more than once in the world than I could not have believed him to be to be married, and that if she were not the most unfortunate man of their own friends, he would have been a very good sort of woman, and I trust it would be as well as I can be. I am sure I am not sorry to see him any thing in his power to marry him\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The two ladies were all gone to the Parsonage Park in London. He was gone to London; and as I met with Mrs. Allen, and asked the next morning to the Parsonage with his father, and the first time of seeing them at the Parsonage and April to London and January, and Mr. Weston had been in the town of January, and Mr. Crawford was in the middle of the house, and the next morning of the first week before she could get the other \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Coles might be the same notice; but that Mr. Elton was no longer astonished to see Robert Martin, and was exceedingly glad to receive him with a happy letter which he would have been used to go. She was not a man of consequence to him to be the best friend of Mr. Yates, and had hoped that she was very fond of her own society, and as I could not help saying, \"How well you do? I think you will be going to Ireland, I \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. They had not received some time of that description before they parted; he was at Mansfield a few days in a way. A quarter of an hour was spent over, and Mr. Pratt's death, and Captain Wentworth was to receive them with her own own good humour in the evening, and being a little disappointed in the morning, and all the rest of the next morning brought her acquaintance with her sister, and as a girl could not but avoid its effect. She had not yet been more amiable than \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Elizabeth had not heard in the idea of the weather. It was not that he was rehearsing; but it was her own; and, moreover, on the whole subject, was at their great absence with his aunt as great an establishment as he might have done. He had much influence from no amusement to make her influence, had a more particular connexion in the country. If Mrs. Grant's really acquainted with the greatest good opinion of her father, she endeavoured to escape an inquiry which, unfortunately flattered by her sister what\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. A quarter of an hour from this staircase were called in easy beauty; and Mary, on seeing the evening before they were put forward with gaiety of spirits and air; and though Mr. Woodhouse had injured his mind, and think that he could not desert her being so far from the mortifications of the earliest four years dinner-nine, she had hoped they had less success that served to be his wife. James resolved to watch, and much of pleasure for repeated the, for which, in spite of her fathers civility, brought\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  12\n",
            "245/245 [==============================] - 22s 88ms/step - loss: 1.9492\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The two youngest of the most distinguished and well-informed child, and Mr. Crawford was at least an age to be the most favourable of the most agreeable to her father and sister. The Dashwoods were now to be active, and Mr. Crawford was soon afterwards obliged to accept the whole of their journey to Kellynch Hall; and Elizabeth was not sorry to be able to go without his own feelings in believing that she was so far from the Colonel Brandon, to her mother and Mrs. Jennings's\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Crawfords were now a good deal of agitation to her cousin and Mr. Crawford. He had been sitting by her, for a fortnight, a more serious and indolent manner, and he had no right to see their relations to be in a state of mind. The two youngest of the most distinguished and disinterested, and a most respectable family of Mrs. Jennings's relations, and in spite of all that Mrs. Norris had been at least a longer time to see him, and Edmund was not in the\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It was a small party above a long way, and a dinner, which had been a pleasant fever; but Mr. Yates, after all the other party, was much agitated by the sight of her sister, and had no idea of her being to be persuaded of his coming into the country; but the others were immediately caught, and Mrs. Norris was soon pleased to see him again. His thoughts were all the others at first. The gentlemen made her turn at the end of the day, and when they parted\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The more of the two were actually expected by the side of Mrs. Jennings's question, she called away with the greatest pain; and the pleasure of seeing her being over, she was all the kind of his sister, when they walked along the sweep gates of a high house to Miss Crawford, to give her the history of his former being in the greatest comfort of his indisposition, but she had been able to advantage to her mothers feelings in this most extraordinary event. She could not but have been included that\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. As Mr. Yates had then ended into the house at the cottage, and Sir Thomas perceived his name of her brother and sister, and having one of the most distinguished and attentive for the express of a third repetition. It was dated quite a year, but Sir Thomas soon afterwards appeared. To know that his character had been so long before her. She was now in high good-humour again, and in spite of herself that she had never even left in more hands in the room. At length \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Maria, the youngest of the very last young of civility, in short, of some party at the door, when a second return; a fortnight at three oclock, a little sent for Mr. Morland; he hoped that would be the greatest satisfaction of being used to share with all, and such was the most sincere, assiduous, more deserving to blame and in the falsehood; for Marianne was absolutely deep to determine whether sunshine had taken a change them both, by remembrance of every thing so apt to think her all to be \n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  13\n",
            "245/245 [==============================] - 22s 88ms/step - loss: 1.8262\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It was a very large party, and Mrs. Norris was soon at the door of the house. The Crawfords were the first to be taken away for a few weeks. The Admiral was not to be prevailed on to spend a few days at Rosings, and to make the best of the Thrush before the Admiral and Miss Crawford, and who was to come to London for a few days, and was received at the same time by the Admiral, who was engaged to dine at Rosings with \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It was a great relief to her to Mrs. Jennings, who was not in the least more gratified by the two young ladies to be in love with her, or the more gentle part of Mrs. Norris, or of any of the others at the door, and Fanny was gone to the house with Mrs. Dashwood, and still in the smallest degree of wonder or censure; but Elinor had known nothing but the truth of her being to be impartiality to him, she must have escaped his journey for ever,\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. The Miss Musgroves were now in the house of Bath, and always to be at large water. The green gate was sudden for a step, and it was a planted wood of two acres, and a bowling-green walk, and the fire was locked; the sun was not a difficulty which Mr. Woodhouse had not so much to say as to Lady Bertram, and with a smile which made her start which she could ever look at, and trying to harden her eyes from the comprehension of Marianne's voice,\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Chapter Xviii At this moment she was in a state of cordiality and invitation, and the young people were all united to each other. The party joined them that Mr. Crawford and Maria were of a younger brother, who joined them, and they judged it all to be of the West Indies. The Monday night was over, which Elizabeth had left her so long ago, and on the watch of Mr. Crawford and Fanny, of being listened to by her dressing-room, and saying, with a \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Emma said no more; and they talked only of this roof, while Mr. Rushworths were called on by her sister at last. As Mrs. Jennings was in a quietness of a regret to her mother, \"My second father does not know him: he does it without much harm in my willingness to engage the honour of letting you.\" Elizabeth was sorry to be amused in a low voice, and meant to think of her more judgment, and words she said: \"I do not think Miss Fairfax has \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. It was soon; he had, indeed, be more rapturous, indeed, the streets of every day, and, if sometimes she could, till their own friends attended, were on the female subject. The next day was spent for ten, with very little curiosity in leaving the Harvilles at Longbourn, though long enough to admire the want of consequence, the property of Kellynch, and of its never all afraid of her heart. The latter had such a compliment--always against herself.--The point which land brought to Elinor was a\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n",
            "epoch:  14\n",
            "245/245 [==============================] - 23s 89ms/step - loss: 1.7001\n",
            "finished training...\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Mr. Woodhouse was not in the way to be expected from Mrs. Batess door. The next morning brought them to Cleveland, and the Miss Dashwoods were ready to proceed in the evening, and Mrs. Norris was beginning to scold her for the sake of her elder sister, to go to her till after Easter. Chapter Xiii The day was soon deferred in the drawing-room. The party broke up with Mrs. Jennings, and her mother, who was engaged to dine at the park, while \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Chapter Viii Mr. Bennet arrived at the door of the house; and on Elinor's side the carriage was forward with the paper and Mr. Elton, the latter looked at her keenly. \"I have been very good in London,\" said Elinor, \"and I believe that he is not very much attached to Miss Smith; but he will be very much concerned if he had been used to be married; and what is all this? I have often observed you the _present_ of Mansfield Park,\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. I have frequently observed it to Mr. Crawford, but I have no doubt that anything else can be done. I am sure I can afford a motive for it. There is no use of my drift at this time, than I can understand myself.\" \"I shall never forget it, I dare say, for I will be very happy if I can be anything in my power. She has been so much prettier, and so this if you would have behaved at her for ever, and I \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Their father had got a very long speech, and he had just applied to her mother to join them again, and they all repaired to the fire, resisting the whole of the baby during the morrow. The next morning brought up stairs by Elinor, who could not spare her father or look at him, and how they never were to be at such a distance from the Kellynch family before her in London, he was to join them in the Lower Park; but she was to be the very first in company \n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. Marianne was in a reverie at the same moment near the door, and in a moment afterwards, telling her that she felt the danger of a look to be dressed, and giving her some little inquiry to Fanny, soliciting a particular friend. We were speaking of each other to be as convenient for my fears, but I think, after a few years I could not have hoped for it, but she has no family interest with him, without any display on the side of that season.\" \"I shall have no butcher\n",
            "The world seemed like such a peaceful place until the magic tree was discovered in London. They had been instructed the gentleman, but all that she should ever forget nothing rather than by the match; but on this Sunday she ventured to think it by Miss Crawford to doubt it. Chapter Viii Henry Crawford called out of the room with a very fine Mr. Price, and dwelling on the staircase by a most interesting character of moral taste to make of conversation with his wife. Some of their stamp and suitableness of honour, and a great deal of very age in the world. There was something\n",
            "samples produced...\n",
            "garbage collected...\n",
            "session cleared (to save memory)...\n"
          ]
        }
      ],
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "model.compile(optimizer=opt, loss=loss)\n",
        "\n",
        "num_epochs_total = 15\n",
        "if restart:\n",
        "  start_epoch = 0\n",
        "else:\n",
        "  start_epoch = epoch_to_pickup\n",
        "for e in range(start_epoch, num_epochs_total):\n",
        "  success = False\n",
        "  while(success == False):\n",
        "    try:\n",
        "      print(\"epoch: \", e)\n",
        "      if e < 10:\n",
        "        new_text = getRandomText(numbooks = 20)\n",
        "      else:\n",
        "        new_text = sherlock_text + getRandomText(numbooks = (num_epochs_total - e)//10)\n",
        "      # new_text = getMyText(files)\n",
        "      dataset = text_to_dataset(new_text)\n",
        "      del new_text\n",
        "      dataset = setup_dataset(dataset)\n",
        "      #opt = tf.keras.optimizers.Adam(learning_rate=0.002*(0.97**e))\n",
        "      #model.compile(optimizer=opt, loss=loss)\n",
        "      model.optimizer.learning_rate.assign(0.002*(0.99**e))\n",
        "      model.fit(dataset, epochs=1, verbose=1)\n",
        "      print(\"finished training...\")\n",
        "      del dataset\n",
        "      #print(\"saving weights...\")\n",
        "      #model.save_weights(path + \"lstm_gru_SH_modelweights_fall2023-random_urls.h5\")\n",
        "      #print(\"weights saved...\")\n",
        "      for temp in [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
        "        produce_sample(model,vectorize_layer,vocabulary, temp, e, 'The world seemed like such a peaceful place until the magic tree was discovered in London.')\n",
        "      print(\"samples produced...\")\n",
        "      gc.collect()\n",
        "      print(\"garbage collected...\")\n",
        "      tf.keras.backend.clear_session()\n",
        "      print(\"session cleared (to save memory)...\")\n",
        "      #tf.config.experimental.reset_all()\n",
        "      success = True\n",
        "    except:\n",
        "      gc.collect()\n",
        "      tf.keras.backend.clear_session()\n",
        "      #tf.config.experimental.reset_all()\n",
        "      try:\n",
        "        del dataset\n",
        "      except:\n",
        "        print(\"dataset already deleted\")\n",
        "      print(\"retrying epoch: \" , e)\n",
        "\n",
        "# Send training complete notification \n",
        "notification.notify(\n",
        "    title='Training Complete!',\n",
        "    app_icon=None,\n",
        "    timeout=10,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RNN_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
